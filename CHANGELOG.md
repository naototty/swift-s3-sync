## 0.1.24 (2018-02-01)

Bug fixes:

    - Fixed shunted S3 listings to return Last-Modified date in the same format
      as Swift.
    - Migration out of S3 buckets sets the X-Timestamp header from Last-Modified
      date (as X-Timestamp is absent).
    - List entire S3 bucket contents when performing migration out of S3 (as
      opposed to assuming a namespace keyed off the hash).

## 0.1.23 (2018-01-31)

Features:

    - Added a swift-s3-verify utility, which allows for validating a provider's
      credentials required by swift-s3-sync by performing
      PUT/GET/HEAD/COPY/DELETE requests against a user-supplied bucket
      (container).
    - Added a swift-s3-migrator daemon, which allows for migrating objects from
      a given Swift cluster into the Swift cluster which has swift-s3-migrator
      deployed. The migration follows a pull model where the remote accounts and
      containers are periodically scanned for new content. The object metadata
      and timestamps are preserved in this process. Some limitations currently
      exist:
      - Dynamic Large Objects are not migrated
      - container ACLs are not propagated
      The migrator can be used against AWS S3 and S3-clones, as well. However,
      that functionality is not well tested.

Bug fixes:

    - Resolved a possible issue where on a GET request through the swift-s3-sync
      shunt the underlying connection may be prematurely re-used.

## 0.1.22 (2017-12-05)

Improvement:

    - Removed the dependency on the `container_crawler` library in the
      `sync_swift` module.

## 0.1.21 (2017-12-05)

Bug fixes:

    - Fix the retries of uploads into Swift by adding support for the `reset()`
      method in the FilePutWrapper and SLOPutWrapper. Previously, Swift would
      never retry a failed upload.
    - No longer issues a PUT object request if the segments container was
      missing and had to be created, but instead we wait until the following
      iteration to retry segment upload.

## 0.1.20 (2017-10-09)

Bug fixes:

    - Update the integration test container dependencies (botocore and
      container-crawler).
    - Improved error handling, by relying on ResponseMetadata:HTTPStatusCode in
      boto errors (as opposed to Error:Code, which may not always be present).
    - Make Content-Type propagation work correctly. The prior attempt included
      it as a user metadata header, which is not what we should be doing.
    - Fix the SLO upload against Google to include the SLO manifest.

## 0.1.19 (2017-10-04)

Features:

    - Support restoring static large objects (SLO) from the remote store (which
      are stored there either as the result of a multipart upload or static
      large objects). The change requires the SLO manifest to be preserved and
      is now uploaded to S3 (and S3 clones) in the .manifests namespace (for
      that account and container).

Bug fixes:

    - If an object is removed from the remote store, no longer fail with 404 Not
      Found (and continue to make progress).
    - Propagate the Content-Type header to the remote store on upload.
    - Fix up for the Swift 2.15.3 release (which repatriated a function we use).

Improvements:

    - Small improvement to the testing container, which will no longer install
      recommended packages.

## 0.1.18 (2017-09-11)

Improvements:

    - Reset the status row when the container policy changes.

## 0.1.17 (2017-09-06)

Features:

    - Support restoring objects from the archive on a GET request. This only
      applies to regular objects. SLO (or multipart objects in S3) are not
      restored, as we do not have the object manifest.

Improvements:

    - Added a docker container to be used for functional testing.

## 0.1.16 (2017-08-23)

Bug fixes:

    - Fix invalid arguments in the call to `get_object_metadata`, which
      manifests during SLO metadata updates (when the object is not changed, but
      the metadata is).

Improvement:

    - Lazy initialize public cloud sessions. This is useful when cloud sync
      reaches the steady state of checking for changes on an infrequently
      changed container. If there are no new objects to upload, no connections
      are created.

## 0.1.15 (2017-08-07)

Bug fixes:

    - Fix listings where the last object has a unicode name.

## 0.1.14 (2017-08-01)

Bug fixes:

    - Handle the "Accept" header correctly when constructing response listings.

## 0.1.13 (2017-07-13)

Bug fixes:

    - Convert container names in the shunt to unicode strings. Otherwise, we
      fail with unicode containers, as they will be (unexpectedly) UTF-8
      encoded.

## 0.1.12 (2017-07-12)

Features:

    - Added "content\_location" to JSON listings, which indicate where the object
      is stored (if not local).
    - Support for HTTP/HTTPS proxy.
    - Allowed log-level to be set through the config.

Bug fixes:

    - Unicode characters are properly handled in account and container names when
      syncing to S3.
    - Fixed paginated listings of archived objects from S3, where previously missing
      hashed prefix could cause the listing to never terminate.
    - Worked around an issue with Google Cloud Storage, where encoding-type has been
      dropped as a valid parameter.
    - Swift to Swift sync is properly supported in the "per-account" case now.
      Containers are auto-created in the remote store and the "cloud container" is
      used as the prefix for the container names.

## 0.1.11 (2017-06-22)

Bug fixes:

    - When returning S3 objects or their metadata, we should unquote the ETag,
      as that would match the expected output from Swift.

## 0.1.10 (2017-06-21)

Bug fixes:

    - The shunt was incorrectly referencing an exception attribute when
      encountering errors from Swift (e.http_status_code vs e.http_status).

## 0.1.9 (2017-06-21)

Bug fixes:

    - The shunt should propagate errors encountered from S3 (e.g. 404) to the
      client, as opposed to always returning 502.

## 0.1.8 (2017-06-21)

Bug fixes:

    - When syncing *all* containers in an account, the middleware needs to use
      the requested container when looking up the object in S3.

## 0.1.7 (2017-06-20)

Features:

    - When uploading data to Amazon S3, AES256 Server-Side encryption will be
      used by default.
    - Added middleware to allow for LIST and GET of objects that may have been
      archived to the remote bucket.

Bug fixes:

    - Supply content-length with Swift objects on PUT. This ensures that we can
      upload a 0-sized object.
    - Fixed Swift DELETE propagation. Previously, DELETE requests would fail due
      to a missing parameter.

Known issues:

    - Sync all containers is currently not working as intended with Swift. It
      places all of the objects in one container. Will address in a subsequent
      release.

## 0.1.6 (2017-06-02)

Bug fixes:

    - Fix an issue that prevents SLO uploads where opening a Swift connection
      before acquiring the S3 client may cause the Swift connection to be closed
      before any bytes are read.
    - Do not serialize on a single Boto session.

## 0.1.5 (2017-06-01)

Bug fixes:

    - Handle deleted objects when DELETE propagation is turned off correctly
      (should be a NOOP, but previously fell through to an attempted upload).
    - Handle "409 Conflict" if attempting to DELETE an object, but it was
      actually already replaced with a new Timestamp.

## 0.1.4 (2017-05-30)

Features:

    - Allow fine(r) grained control of object movement through `copy_after`,
      `retain_local`, and `propagate_delete` options. `copy_after` defers action
      on the rows until after a specified number of seconds has expired since
      the last object update; `retain_local` determines whether the object
      should be removed after copying to the remote store; `propagate_delete`
      controls whether DELETE requests against the cluster should show up on the
      remote endpoint. For example, one could configure Cloud Sync in archive
      mode, by turning off DELETE propagation and local copy retention, while
      defering the copy action for a set number of days until the archival date.

Bug fixes:

    - A missing object should not generate an exception -- and stop Cloud Sync
      -- when attempting to upload. The exception will now be ignored.

## 0.1.3 (2017-05-08)

Improvement:

    - Support new version of the ContainerCrawler (0.0.3).

## 0.1.2 (2017-04-19)

Features:

    - Implemented support for syncing to Swift. Does not support DLO, but does
      have parity with S3 sync (propagates PUT, POST, DELETE, and supports
      SLOs). Swift can be enabled by passing the option "protocol" with the
      value "swift" in the configuration for a mapping.

Bug fixes:

    - Fixed a broken import, which prevented the daemon from starting.
    - Restricted the requests Sessions to be used once per worker (as opposed to
      being shared across workers).

## 0.1.1 (2017-03-22)

Improvements:

    - Add boto3/botocore logging. This is particularly useful at debug level to
      observe the submitted requests/responses.
    - Added a user agent string for the Google Partner Network.

## 0.1.0 (2017-03-20)

Features:

    - Added SLO support in AWS S3 and Google Cloud Storage. For AWS S3 (and
      clones), SLO is converted to an MPU. Ranges are not supported in SLO
      manifest. If there is a mismatch between the smallest S3 part and Swift,
      i.e. allowing for a segment size < 5MB in Swift, the manifest will fail to
      upload. GCS uploads are converted to a single object, as it has a 5TB
      upload limit.

Improvements:

    - Move s3-sync to using the ContainerCrawler framework.

## 0.0.9 (2016-12-12)

Bug fixes:

    - Fix error handling, where some workers could quit without indicating
      completion of a task, causing the main process to hang.
    - More unicode support fixes.

## 0.0.8 (2016-10-19)

Bug fixes:

    - Properly encode unicode characters in object names and metadata.
    - The `--once` option runs exactly once now.

## 0.0.7 (2016-09-28)

Features:

    - Added support for non-Amazon providers, where we fall back to v2 signer.
    - Glacier integration: objects are re-uploaded if their metadata changes, as
      the metadata is immutable in Glacier.

Bug fixes:

    - Fixed object deletion. Previously, deletes would repeatedly fail and the
      daemon would not make progress.
    - Fixed a bug where `upload_object()` would be called after
      `delete_object()` (even though the object does not exist)

## 0.0.6 (2016-09-05)

Features:

    - Added concurrent uploads, through green threads.

Bug fixes:

    - Avoid extra seeks when attempting to rewind the object which has not been
      read (i.e. calling seek(0) after opening the object).
    - Close the object stream at the end of transfers.

## 0.0.5 (2016-08-16)

Features:

    - Add support for AWS-v4 chunked transfers.

Improvements:

    - Track the database ID and bucket name. If the DB drive crashes and it is
      rebuilt, this will cause the node to re-validate the data already
      uploaded.

    - Exit with status "0" if the config file does not exist. This is important,
      as otherwise a process monitoring system may restart the daemon, on the
      assumption that it encountered an error.

Bug fixes:

    - Configuring the cloud sync daemon for a new bucket resets the sync
      progress.

## 0.0.4 (2016-07-29)

Bug fixes:

    - Account for S3 quoting etags when comparing to the Swift etag (which would
      previously result in repeated uploads).

## 0.0.3 (2016-07-26)

Improvements:

    - Only use the account/container when computing the bucket prefix.
    - Add retry on errors (as opposed to exiting).
    - Early termination if there are no containers to sync.
